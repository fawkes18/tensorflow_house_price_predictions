{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os \n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras import regularizers\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "\n",
    "import statistics\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C://Users/Marco/Downloads/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['ExterQual'] == 'Ex','ExterQual'] = 5\n",
    "df.loc[df['ExterQual'] == 'Gd','ExterQual'] = 4\n",
    "df.loc[df['ExterQual'] == 'TA','ExterQual'] = 3\n",
    "df.loc[df['ExterQual'] == 'Fa','ExterQual'] = 2\n",
    "\n",
    "df.loc[df['BsmtFinType1'] == 'GLQ','BsmtFinType1'] = 6\n",
    "df.loc[df['BsmtFinType1'] == 'ALQ','BsmtFinType1'] = 5\n",
    "df.loc[df['BsmtFinType1'] == 'BLQ','BsmtFinType1'] = 4\n",
    "df.loc[df['BsmtFinType1'] == 'Rec','BsmtFinType1'] = 3\n",
    "df.loc[df['BsmtFinType1'] == 'LwQ','BsmtFinType1'] = 2\n",
    "df.loc[df['BsmtFinType1'] == 'Unf','BsmtFinType1'] = 1 \n",
    "\n",
    "df.loc[df['BsmtQual'] == 'Ex','BsmtQual'] = 5\n",
    "df.loc[df['BsmtQual'] == 'Gd','BsmtQual'] = 4\n",
    "df.loc[df['BsmtQual'] == 'TA','BsmtQual'] = 3\n",
    "df.loc[df['BsmtQual'] == 'Fa','BsmtQual'] = 2\n",
    "df.loc[df['BsmtQual'] == 'Po','BsmtQual'] = 1  \n",
    "\n",
    "df.loc[df['Functional'] == 'Typ','Functional'] = 7\n",
    "df.loc[df['Functional'] == 'Min1','Functional'] = 6\n",
    "df.loc[df['Functional'] == 'Min2','Functional'] = 5\n",
    "df.loc[df['Functional'] == 'Mod','Functional'] = 4\n",
    "df.loc[df['Functional'] == 'Maj1','Functional'] = 3\n",
    "df.loc[df['Functional'] == 'Maj2','Functional'] = 2\n",
    "df.loc[df['Functional'] == 'Sev','Functional'] = 1\n",
    "\n",
    "df.loc[df['HeatingQC'] == 'Ex','HeatingQC'] = 5\n",
    "df.loc[df['HeatingQC'] == 'Gd','HeatingQC'] = 4\n",
    "df.loc[df['HeatingQC'] == 'TA','HeatingQC'] = 3\n",
    "df.loc[df['HeatingQC'] == 'Fa','HeatingQC'] = 2\n",
    "df.loc[df['HeatingQC'] == 'Po','HeatingQC'] = 1  \n",
    "\n",
    "df.loc[df['FireplaceQu'] == 'Ex','FireplaceQu'] = 5\n",
    "df.loc[df['FireplaceQu'] == 'Gd','FireplaceQu'] = 4\n",
    "df.loc[df['FireplaceQu'] == 'TA','FireplaceQu'] = 3\n",
    "df.loc[df['FireplaceQu'] == 'Fa','FireplaceQu'] = 2\n",
    "df.loc[df['FireplaceQu'] == 'Po','FireplaceQu'] = 1 \n",
    "\n",
    "\n",
    "df1=df.select_dtypes(exclude=['object'])\n",
    "\n",
    "df_dummies=pd.concat([pd.get_dummies(df['ExterQual'], prefix='ExterQual',drop_first=True),\n",
    "                      pd.get_dummies(df['BsmtQual'], prefix='BsmtQual',drop_first=True),\n",
    "                      pd.get_dummies(df['HeatingQC'], prefix='HeatingQC',drop_first=True),\n",
    "                      pd.get_dummies(df['BsmtFinType1'], prefix='BsmtFinType1',drop_first=True),\n",
    "                      pd.get_dummies(df['Functional'], prefix='Functional',drop_first=True),\n",
    "                      pd.get_dummies(df['FireplaceQu'], prefix='FireplaceQu',drop_first=True)],axis=1)\n",
    "\n",
    "df_metric=df1['LotFrontage LotArea YearBuilt GrLivArea FullBath Fireplaces GarageArea SalePrice'.split()]\n",
    "\n",
    "df_final=pd.concat([df_dummies, df1['LotFrontage LotArea YearBuilt GrLivArea FullBath Fireplaces GarageArea SalePrice'.split()]],axis=1)\n",
    "df_final = df_final[df_final['GrLivArea'] < 4000]\n",
    "df_final.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_final.drop(['SalePrice'], axis=1)\n",
    "y_level = df_final['SalePrice']\n",
    "y_log=np.log(df_final['SalePrice'])\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train , x_test , y_level_train , y_level_test = train_test_split(X, y_level, test_size =0.3, random_state =77)\n",
    "x_train , x_test , y_log_train , y_log_test = train_test_split(X, y_log, test_size =0.3, random_state =77)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "SC= StandardScaler().fit(x_train['LotFrontage LotArea YearBuilt GrLivArea FullBath Fireplaces GarageArea'.split()])\n",
    "x_train['LotFrontage LotArea YearBuilt GrLivArea FullBath Fireplaces GarageArea'.split()]=SC.transform(x_train['LotFrontage LotArea YearBuilt GrLivArea FullBath Fireplaces GarageArea'.split()])\n",
    "x_test['LotFrontage LotArea YearBuilt GrLivArea FullBath Fireplaces GarageArea'.split()]=SC.transform(x_test['LotFrontage LotArea YearBuilt GrLivArea FullBath Fireplaces GarageArea'.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  \n",
    "config.log_device_placement = True \n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model):\n",
    "    history = model.fit(x_train, y_level_train, batch_size = 256, verbose=1, epochs=500)\n",
    "\n",
    "def zero_layer(n1, dropout, opt, learning_rate, regularizer1, reg_rate1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n1, input_dim=32, kernel_initializer='normal', activation='relu', use_bias=True,\n",
    "                   kernel_regularizer=regularizer1(reg_rate1)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation='linear', use_bias=True))\n",
    "    model.compile(optimizer=opt(lr=learning_rate), loss='mean_absolute_error', metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "def one_layer(n1, n2, dropout1, dropout2, opt, learning_rate, regularizer1, regularizer2, reg_rate1, reg_rate2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n1, input_dim=32, kernel_initializer='normal', activation='relu', use_bias=True, kernel_regularizer=regularizer1(reg_rate1)))\n",
    "    model.add(Dropout(dropout1))\n",
    "    model.add(Dense(n2, kernel_initializer='normal', activation='relu', use_bias=True, kernel_regularizer=regularizer2(reg_rate2)))\n",
    "    model.add(Dropout(dropout2))\n",
    "    model.add(Dense(1, activation='linear', use_bias=True))\n",
    "    model.compile(optimizer=opt(lr=learning_rate), loss='mean_absolute_error', metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "def two_layer(n1, n2, n3, dropout1, dropout2, dropout3, opt, learning_rate, regularizer1, regularizer2, regularizer3):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(n1, input_dim=32, kernel_initializer='normal', activation='relu', use_bias=True, kernel_regularizer=regularizer1))\n",
    "    model.add(Dropout(dropout1))\n",
    "    model.add(Dense(n2, kernel_initializer='normal', activation='relu', use_bias=True, kernel_regularizer=regularizer2))\n",
    "    model.add(Dropout(dropout2))\n",
    "    model.add(Dense(n3, kernel_initializer='normal', activation='relu', use_bias=True, kernel_regularizer=regularizer3))\n",
    "    model.add(Dropout(dropout3))\n",
    "    model.add(Dense(1, activation='linear', use_bias=True))\n",
    "    model.compile(optimizer=opt(lr=learning_rate), loss='mean_absolute_error', metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Wie viele Layer / Neuronen pro Layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlist_0 = [82240 + 16448*i for i in range(5)]\n",
    "\n",
    "results_0 = pd.DataFrame(columns = ['model', 'mse'])\n",
    "\n",
    "trials_0 = 5\n",
    "\n",
    "for j in range(trials_0):\n",
    "    for n in nlist_0:\n",
    "        d = {}\n",
    "        model = zero_layer(n, 0, RMSprop, 0.006, regularizers.l1, 0.00)\n",
    "        run_model(model)\n",
    "        pred = model.predict(x_test)\n",
    "        d['model'] = str(n) + '_neurons'\n",
    "        d['mse'] = np.sqrt(mean_squared_error(y_level_test, pred))\n",
    "        results_0 = results_0.append(d, ignore_index=True)\n",
    "        \n",
    "pickle.dump(results_0, open(\"results_0.p\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results0_vals = results_0['model'].unique().tolist()\n",
    "\n",
    "for model in results0_vals:\n",
    "    mean = results_0['mse'].loc[results_0['model'] == model].mean()\n",
    "    std = statistics.stdev(results_0['mse'].loc[results_0['model'] == model])\n",
    "    print(f'model: {model}, mse: {mean}, std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlist_1 = [(2048, 1024), (1024, 512), (512, 256), (256, 128), (128, 64), (64, 32)]\n",
    "\n",
    "results_1 = pd.DataFrame(columns=['model', 'mse'])\n",
    "\n",
    "trials_1 = 5\n",
    "\n",
    "for j in range(trials_1):\n",
    "    for (n1, n2) in nlist_1:\n",
    "        d = {}\n",
    "        model = one_layer(n1, n2, 0, 0, RMSprop, 0.006, regularizers.l1, regularizers.l1, 0.00, 0.00)\n",
    "        run_model(model)\n",
    "        pred = model.predict(x_test)\n",
    "        d['model'] = str(n1) + 'x' + str(n2) + '_neurons'\n",
    "        d['mse'] = np.sqrt(mean_squared_error(y_level_test, pred))\n",
    "        results_1 = results_1.append(d, ignore_index=True)\n",
    "\n",
    "pickle.dump(results_1, open('results_1', 'wb'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1_vals = results_1['model'].unique().tolist()\n",
    "\n",
    "for model in results1_vals:\n",
    "    mean = results_1['mse'].loc[results_1['model'] == model].mean()\n",
    "    std = statistics.stdev(results_1['mse'].loc[results_1['model'] == model])\n",
    "    print(f'model: {model}, mse: {mean}, std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlist_2 = [(1024, 512, 256), (512, 256, 128), (256, 128, 64), (128, 64, 32), (64, 32, 16)]\n",
    "\n",
    "results_2 = pd.DataFrame(columns=['model', 'mse'])\n",
    "\n",
    "trials_2 = 5\n",
    "\n",
    "for j in range(trials_2):\n",
    "    for (n1, n2, n3) in nlist_2:\n",
    "        d = {}\n",
    "        model = two_layer(n1, n2, n3, 0, 0, 0, RMSprop, 0.006, regularizers.l1, regularizers.l1, regularizers.l1, 0.00, 0.00, 0.00)\n",
    "        run_model(model)\n",
    "        pred = model.predict(x_test)\n",
    "        d['model'] = str(n1) + 'x' + str(n2) + 'x' + str(n3) + '_neurons'\n",
    "        d['mse'] = np.sqrt(mean_squared_error(y_level_test, pred))\n",
    "        results_2 = results_2.append(d, ignore_index=True)\n",
    "        \n",
    "pickle.dump(results_2, open('results_2.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2_vals = results_2['model'].unique().tolist()\n",
    "\n",
    "for model in results2_vals:\n",
    "    mean = results_2['mse'].loc[results_2['model'] == model].mean()\n",
    "    std = statistics.stdev(results_2['mse'].loc[results_2['model'] == model])\n",
    "    print(f'model: {model}, mse: {mean}, std: {std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2. Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dropout_vals = [0.0, 0.1, 0.2, 0.3]\n",
    "            \n",
    "dropout_results0 = pd.DataFrame(columns = ['model', 'mse'])\n",
    "\n",
    "for j in range(5):\n",
    "    for i in dropout_vals:\n",
    "        d = {}\n",
    "        model = zero_layer(98688, i, RMSprop, 0.006, regularizers.l1, 0.00)\n",
    "        run_model(model)\n",
    "        pred = model.predict(x_test)\n",
    "        d['model'] = 'dropout_' + str(i)\n",
    "        d['mse'] = np.sqrt(mean_squared_error(y_level_test, pred))\n",
    "        dropout_results0 = dropout_results0.append(d, ignore_index=True)\n",
    "        \n",
    "pickle.dump(dropout_results0, open('dropout_results0', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout0_vals = dropout_results0['model'].unique().tolist()\n",
    "\n",
    "for model in dropout0_vals:\n",
    "    mean = dropout_results0['mse'].loc[dropout_results0['model'] == model].mean()\n",
    "    std = statistics.stdev(dropout_results0['mse'].loc[dropout_results0['model'] == model])\n",
    "    print(f'model: {model}, mse: {mean}, std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_pairs = []\n",
    "\n",
    "for i in dropout_vals:\n",
    "    for j in dropout_vals:\n",
    "        list1 = [i, j]\n",
    "        if list1 not in dropout_pairs:\n",
    "            dropout_pairs.append(list1)\n",
    "        list2 = [j, i]\n",
    "        if list2 not in dropout_pairs:\n",
    "            dropout_pairs.append(list2)\n",
    "\n",
    "dropout_results1 = pd.DataFrame(columns = ['model', 'mse'])\n",
    "\n",
    "for j in range(5):\n",
    "    for i in dropout_pairs:\n",
    "        d = {}\n",
    "        model = one_layer(1024, 512, i[0], i[1], RMSprop, 0.006, regularizers.l1, regularizers.l1, 0.00, 0.00)\n",
    "        run_model(model)\n",
    "        pred = model.predict(x_test)\n",
    "        d['model'] = 'dropout_' + str(i[0]) + '_' + str(i[1])\n",
    "        d['mse'] = np.sqrt(mean_squared_error(y_level_test, pred))\n",
    "        dropout_results1 = dropout_results1.append(d, ignore_index=True)\n",
    "        \n",
    "pickle.dump(dropout_results1, open('dropoute_results1', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout1_vals = dropout_results1['model'].unique().tolist()\n",
    "\n",
    "for model in dropout1_vals:\n",
    "    mean = dropout_results1['mse'].loc[dropout_results1['model'] == model].mean()\n",
    "    std = statistics.stdev(dropout_results1['mse'].loc[dropout_results1['model'] == model])\n",
    "    print(f'model: {model}, mse: {mean}, std: {std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = [Adam, RMSprop]\n",
    "learning_rates = [0.004, 0.005, 0.006, 0.007]\n",
    "\n",
    "opt_list = [[i, j] for i in optimizers for j in learning_rates]\n",
    "            \n",
    "opt_results0 = pd.DataFrame(columns=['model', 'mse'])\n",
    "            \n",
    "for j in range(5):\n",
    "    for i in opt_list:\n",
    "        d = {}\n",
    "        model = zero_layer(98688, 0.1, i[0], i[1], regularizers.l1, 0.00)\n",
    "        run_model(model)\n",
    "        pred = model.predict(x_test)\n",
    "        d['model'] = 'zero_layer_' + str(i[0]).split('.', -1)[-1].split(\"'\")[0] + f'_lr_{i[1]}'\n",
    "        d['mse'] = np.sqrt(mean_squared_error(y_level_test, pred))\n",
    "        opt_results0 = opt_results0.append(d, ignore_index=True)\n",
    "        \n",
    "pickle.dump(opt_results0, open('opt_results0', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt0_vals = opt_results0['model'].unique().tolist()\n",
    "\n",
    "for model in opt0_vals:\n",
    "    mean = opt_results0['mse'].loc[opt_results0['model'] == model].mean()\n",
    "    std = statistics.stdev(opt_results0['mse'].loc[opt_results0['model'] == model])\n",
    "    print(f'model: {model}, mse: {mean}, std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_results1 = pd.DataFrame(columns=['model', 'mse'])\n",
    "\n",
    "for j in range(5):\n",
    "    for i in opt_list:\n",
    "        d = {}\n",
    "        model = one_layer(1024, 512, 0.1, 0.3, i[0], i[1], regularizers.l1, regularizers.l1, 0.00, 0.00)\n",
    "        run_model(model)\n",
    "        pred = model.predict(x_test)\n",
    "        d['model'] = 'one_layer_' + str(i[0]).split('.', -1)[-1].split(\"'\")[0] + f'_lr_{i[1]}'\n",
    "        d['mse'] = np.sqrt(mean_squared_error(y_level_test, pred))\n",
    "        opt_results1 = opt_results1.append(d, ignore_index=True)\n",
    "        \n",
    "pickle.dump(opt_results1, open('opt_result1.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt1_vals = opt_results1['model'].unique().tolist()\n",
    "\n",
    "for model in opt1_vals:\n",
    "    mean = opt_results1['mse'].loc[opt_results1['model'] == model].mean()\n",
    "    std = statistics.stdev(opt_results1['mse'].loc[opt_results1['model'] == model])\n",
    "    print(f'model: {model}, mse: {mean}, std: {std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Regularisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regul = [regularizers.l1, regularizers.l2]\n",
    "reg_vals = [0.007, 0.008, 0.009, 0.01]\n",
    "\n",
    "reg_list = [[r, j] for r in regul for j in reg_vals]\n",
    "\n",
    "reg_results0 = pd.DataFrame(columns=['model', 'mse'])\n",
    "\n",
    "for j in range(5):\n",
    "    for i in reg_list:\n",
    "        d = {}\n",
    "        model = zero_layer(98688, 0.1, RMSprop, 0.007, i[0], i[1], regularizers.l1, 0.00)\n",
    "        run_model(model)\n",
    "        pred = model.predict(x_test)\n",
    "        d['model'] = 'zero_layer_' + str(i[0]).split('.', -1)[-1].split(\"'\")[0] + f'_({i[1]})'\n",
    "        d['mse'] = np.sqrt(mean_squared_error(y_level_test, pred))\n",
    "        reg_results0 = reg_results0.append(d, ignore_index=True)\n",
    "\n",
    "pickle.dump(reg_results0, open('reg_results0.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_vals0 = reg_results0['model'].unique().tolist()\n",
    "\n",
    "for model in reg_vals0:\n",
    "    mean = reg_results0['mse'].loc[reg_results0['model'] == model].mean()\n",
    "    std = statistics.stdev(reg_results0['mse'].loc[reg_results0['model'] == model])\n",
    "    print(f'model: {model}, mean: {mean}, std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_list1 = [[r, s, j, i] for r in regul for s in regul for j in reg_vals for i in reg_vals]\n",
    "\n",
    "reg_results1 = pd.DataFrame(columns=['model', 'mse'])\n",
    "\n",
    "for j in range(5):\n",
    "    for i in reg_list1:\n",
    "        d = {}\n",
    "        model = one_layer(1024, 512, 0.1, 0.3, RMSprop, 0.006, i[0], i[1], i[2], i[3], regularizers.l1, regularizers.l1, 0.00, 0.00)\n",
    "        run_model(model)\n",
    "        pred = model.predict(x_test)\n",
    "        d['model'] = 'one_layer_' + str(i[0]).split('.', -1)[-1].split(\"'\")[0] + f'({i[2]})_' + str(i[1]).split('.', -1)[-1].split(\"'\")[0] + f'({i[3]})'\n",
    "        d['mse'] = np.sqrt(mean_squared_error(y_level_test, pred))\n",
    "        reg_results1 = reg_results1.append(d, ignore_index=True)\n",
    "        \n",
    "pickle.dump(reg_results1, open('reg_results1.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_vals1 = reg_results1['model'].unique().tolist()\n",
    "\n",
    "for model in reg_vals1:\n",
    "    mean = reg_results1['mse'].loc[reg_results1['model'] == model].mean()\n",
    "    std = statistics.stdev(reg_results1['mse'].loc[reg_results1['model'] == model])\n",
    "    print(f'model: {model}, mean: {mean}, std: {std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Epochs / Batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model2(model, batch_size, epochs):\n",
    "    history = model.fit(x_train, y_level_train, batch_size=batch_size, verbose=0, epochs=epochs)\n",
    "\n",
    "ep = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "\n",
    "epoch_results1 = pd.DataFrame(columns=['epochs', 'mse'])\n",
    "    \n",
    "for j in range(5):\n",
    "    print(f'full_iteration: {j+1} of 5')\n",
    "    for i in ep:\n",
    "        d = {}\n",
    "        model = one_layer(1024, 512, 0.1, 0.3, RMSprop, 0.006, regularizers.l1, regularizers.l1, 0.01, 0.009)\n",
    "        run_model2(model, 256, i)\n",
    "        pred = model.predict(x_test)\n",
    "        d['epochs'] = int(i)\n",
    "        d['mse'] = np.sqrt(mean_squared_error(y_level_test, pred))\n",
    "        epoch_results1 = epoch_results1.append(d, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_vals1 = epoch_results1['epochs'].unique().tolist()\n",
    "\n",
    "for val in epoch_vals1:\n",
    "    mean = epoch_results1['mse'].loc[epoch_results1['epochs'] == val].mean()\n",
    "    std = statistics.stdev(epoch_results1['mse'].loc[epoch_results1['epochs'] == val])\n",
    "    print(f'epochs: {val}, mse: {mean}, std: {std} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_results0 = pd.DataFrame(columns=['epochs', 'mse'])\n",
    "\n",
    "\n",
    "for j in range(5):\n",
    "    print(f'full_iteration: {j+1} of 5')\n",
    "    for i in ep:\n",
    "        d = {}\n",
    "        model = zero_layer(98688, 0.1, RMSprop, 0.007, regularizers.l1, 0)\n",
    "        run_model2(model, 256, i)\n",
    "        pred = model.predict(x_test)\n",
    "        d['epochs'] = int(i)\n",
    "        d['mse'] = np.sqrt(mean_squared_error(y_level_test, pred))\n",
    "        epoch_results0 = epoch_results0.append(d, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_vals0 = epoch_results0['epochs'].unique().tolist()\n",
    "\n",
    "for val in epoch_vals0:\n",
    "    mean = epoch_results0['mse'].loc[epoch_results0['epochs'] == val].mean()\n",
    "    std = statistics.stdev(epoch_results0['mse'].loc[epoch_results0['epochs'] == val])\n",
    "    print(f'epochs: {val}, mse: {mean}, std: {std} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [128, 256, 512, 1024]\n",
    "\n",
    "batch_results = pd.DataFrame(columns=['batch_size', 'mse'])\n",
    "\n",
    "for j in range(15):\n",
    "    print(f'full_iteration: {j+1} of 15')\n",
    "    for i in batch_sizes:\n",
    "        d = {}\n",
    "        model = one_layer(1024, 512, 0.1, 0.3, RMSprop, 0.006, regularizers.l1, regularizers.l1, 0.01, 0.009)\n",
    "        run_model2(model, i, 400)\n",
    "        pred = model.predict(x_test)\n",
    "        d['batch_size'] = int(i)\n",
    "        d['mse'] = np.sqrt(mean_squared_error(y_level_test, pred))\n",
    "        batch_results = batch_results.append(d, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_vals = batch_results['batch_size'].unique().tolist()\n",
    "\n",
    "for val in batch_vals:\n",
    "    mean = batch_results['mse'].loc[batch_results['batch_size'] == val].mean()\n",
    "    std = statistics.stdev(batch_results['mse'].loc[batch_results['batch_size'] == val])\n",
    "    print(f'batch_size: {val}, mse: {mean}, std: {std} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. Ergebnis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = one_layer(1024, 512, 0.1, 0.3, RMSprop, 0.006, regularizers.l1, regularizers.l1, 0.01, 0.009)\n",
    "run_model2(model, 256, 400)\n",
    "pred = model.predict(x_test)\n",
    "mse = np.sqrt(mean_squared_error(y_level_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
